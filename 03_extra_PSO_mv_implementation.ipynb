{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb31ed15",
   "metadata": {},
   "source": [
    "# $PSO_{mv}$ implementation #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5986b",
   "metadata": {},
   "source": [
    "In this notebook it is presented a **naive implementation** of the algorithm described in F. Wang, H. Zhang, A. Zhou *A particle swarm optimization algorithm for mixed-variable optimization problems* which combines two variants of the PSO algorithm to evolve both the discrete and the continuous part of a swarm to tackle mixed discrete-integer optimization problems. This implementation is used to compare the optimization results of our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbb9088",
   "metadata": {},
   "source": [
    "Main ideas behind the algorithm according to the paper\n",
    "\n",
    "<img src=\"./images/pso_mv.png\" alt=\"alternative text\" width=\"950\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7196d705",
   "metadata": {},
   "source": [
    "## Code ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b300d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0a9b289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 02_GA-PSO_on_artificial_test_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d770aaf",
   "metadata": {},
   "source": [
    "### Continuous part ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e42eb5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_PSO(element, index, velocity, population, particle_best, d_discr, d_cont, w, minimum, maximum, cog = 2):\n",
    "    '''\n",
    "    Performs the Continuous Reproduction Method described above\n",
    "    '''\n",
    "    \n",
    "    #all arrays are assumed sorted according to their particle_best value\n",
    "    N = len(population)\n",
    "    \n",
    "    for j in range(d_discr,d_discr+d_cont):\n",
    "        r = np.random.randint(index,N)\n",
    "        randm = np.random.uniform(0,1)\n",
    "        \n",
    "        #update velocity\n",
    "        velocity[j-d_discr]=w[index]*velocity[j-d_discr]+cog*randm*(particle_best[r][j]-element[j])\n",
    "        \n",
    "        #update position\n",
    "        element[j]+=velocity[j-d_discr]\n",
    "        \n",
    "        #boundaries\n",
    "        if element[j]>maximum:\n",
    "            element[j]=maximum\n",
    "            velocity[j-d_discr]=-(velocity[j-d_discr])\n",
    "        if element[j]<minimum:\n",
    "            element[j]=minimum\n",
    "            velocity[j-d_discr]=-(velocity[j-d_discr])\n",
    "            \n",
    "                        \n",
    "    #return updated element and its velocity\n",
    "    return element, velocity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "acb2b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_PSO(element, index, prob, population, particle_best, d_discr,d_cont, alpha, num_values, poss_values):\n",
    "    N = len(population)\n",
    "    count = np.zeros((d_discr, num_values))\n",
    "\n",
    "    #convert each list in particle_best to a numpy array and stack them vertically\n",
    "    particle_best_np = np.vstack([np.array(lst) for lst in particle_best])\n",
    "    \n",
    "    const_prob=np.array([[1/num_values] * num_values for _ in range(d_discr)])\n",
    "\n",
    "    for j in range(d_discr):\n",
    "        count[j] = np.sum(np.isclose(particle_best_np[int(N/2):, j][:, None], poss_values[None, :]), axis=0)\n",
    "        count_int = count[j].astype(int)\n",
    "\n",
    "        prob_np = np.array(prob[j])\n",
    "        const_prob_values = np.array([1/num_values] * num_values) \n",
    "               \n",
    "        #ensure prob[j] is a NumPy array before performing arithmetic operations\n",
    "        prob[j] = alpha[index] * prob_np + (0.8 - alpha[index]) * count_int / (N/2)+0.2*const_prob_values\n",
    "        \n",
    "\n",
    "    #update only the first d_discr values in element according to the probabilities obtained\n",
    "    element[:d_discr] = [poss_values[np.random.choice(num_values, p=prob[j])] for j in range(d_discr)]\n",
    "\n",
    "    return element, prob\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2e1981a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import cauchy\n",
    "\n",
    "def tuning(w_avg,alpha_avg):\n",
    "    '''\n",
    "    w_avg and alpha_avg are the average value of historical best parameters\n",
    "    '''\n",
    "    \n",
    "    rand= np.random.uniform(0,1)\n",
    "    \n",
    "    if rand<0.5:\n",
    "        w = cauchy.rvs(loc=w_avg, scale=0.1, size=1)[0]\n",
    "        alpha = cauchy.rvs(loc=alpha_avg, scale=0.1, size=1)[0]\n",
    "        if alpha<=0:\n",
    "            alpha=0\n",
    "        if alpha>=0.8:\n",
    "            alpha=0.8\n",
    "        if w<0:\n",
    "            w=0\n",
    "        if w>1.5:\n",
    "            w=1.5\n",
    "        \n",
    "    else:         \n",
    "        w = np.random.normal(loc=w_avg, scale=math.sqrt(0.1))\n",
    "        alpha = np.random.normal(loc=alpha_avg, scale=math.sqrt(0.1))\n",
    "        if alpha<=0:\n",
    "            alpha=0\n",
    "        if alpha>=0.8:\n",
    "            alpha=0.8\n",
    "        if w<0:\n",
    "            w=0\n",
    "        if w>1.5:\n",
    "            w=1.5    \n",
    "        \n",
    "    return w, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ea547514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_sorting(particle_number,pop, vals, best_pos, best_vals,velocities,w,alpha,w_avg,alpha_avg):\n",
    "    #sort best_vals in decreasing order\n",
    "    sorted_indices = sorted(range(len(best_vals)), key=lambda k: best_vals[k], reverse=True)\n",
    "\n",
    "    #sort everything based on the sorted order of best_vals\n",
    "    pop = [pop[i] for i in sorted_indices]\n",
    "    vals = [vals[i] for i in sorted_indices]\n",
    "    best_pos = [best_pos[i] for i in sorted_indices]\n",
    "    particle_number = [particle_number[i] for i in sorted_indices]\n",
    "    velocities = [velocities[i] for i in sorted_indices]\n",
    "    w = [w[i] for i in sorted_indices]\n",
    "    alpha = [alpha[i] for i in sorted_indices]\n",
    "    w_avg = [w_avg[i] for i in sorted_indices]\n",
    "    alpha_avg = [alpha_avg[i] for i in sorted_indices]\n",
    "    best_vals = sorted(best_vals, reverse=True)\n",
    "\n",
    "    return particle_number,pop, vals, best_pos, best_vals, velocities, w, alpha, w_avg,alpha_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9c718f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_mv(epochs,function,rot_matrix,n_pop,d_discr,d_cont,minimum,maximum,granularity,max_fitness_eval=100000):\n",
    "    '''\n",
    "    Main function for the PSO_mv algorithm\n",
    "    '''\n",
    "    \n",
    "    #initialization\n",
    "    population = np.array(initialization(n_pop,d_discr,d_cont,minimum,maximum,granularity))     \n",
    "    \n",
    "    #number of fitness evaluation\n",
    "    f_eval = 0\n",
    "    \n",
    "    #evaluation\n",
    "    values, f_eval = evaluation(function,population,f_eval,d_discr,d_cont,rot_matrix,max_fitness_eval)\n",
    "    values=np.array(values)\n",
    "    \n",
    "       \n",
    "    particle_number = np.array(list(range(n_pop)))\n",
    "    \n",
    "    #intialize particle_best, at the beginning\n",
    "    particle_best_position= np.array(copy.copy(population))\n",
    "    particle_best_values = np.array(copy.copy(values))\n",
    "    \n",
    "    #initial velocities for the continuous part\n",
    "    velocities = np.array([[0] * d_cont for _ in range(n_pop)])\n",
    "        \n",
    "     \n",
    "    #initial probability for the discrete part\n",
    "    probabilities=np.array([[1/granularity] * granularity for _ in range(d_discr)])\n",
    "    \n",
    "    #initialize w and alphas\n",
    "    w = [0.5] * n_pop\n",
    "    alpha = [0.5] * n_pop\n",
    "    \n",
    "    w_avg = [0.5] * n_pop\n",
    "    alpha_avg = [0.5] * n_pop\n",
    "    \n",
    "    #sorting population according to their particle_best value\n",
    "    particle_number, population, values, particle_best_position, particle_best_values,velocities,w,alpha,w_avg,alpha_avg = pop_sorting(\n",
    "                                                                                        particle_number, population,\n",
    "                                                                                        values, particle_best_position, \n",
    "                                                                                        particle_best_values,velocities,\n",
    "                                                                                        w,alpha,w_avg,alpha_avg)\n",
    "    \n",
    "    \n",
    "    #values ordered according to particle_number\n",
    "    w_hist = [[0.5] for _ in range(n_pop)]\n",
    "    alpha_hist = [[0.5] for _ in range(n_pop)]\n",
    "    \n",
    "    tot_best=min(particle_best_values)\n",
    "    \n",
    "    bmrk=[tot_best]\n",
    "    f_evaluations=[f_eval]\n",
    "     \n",
    "      \n",
    "    for epoch in range(0,epochs):\n",
    "        \n",
    "        sort_ind = sorted(range(len(particle_number)), key=lambda k: particle_number[k], reverse=False)\n",
    "\n",
    "        prev_values = [values[i] for i in sort_ind]\n",
    "        \n",
    "        #extract the w and alpha parameter\n",
    "        for q in range(0,n_pop):\n",
    "            w[q], alpha[q] = tuning(w_avg[q],alpha_avg[q])              \n",
    "            \n",
    "        if min(particle_best_values)<tot_best:\n",
    "                tot_best= min(particle_best_values)\n",
    "            \n",
    "        if epoch%15==0:\n",
    "            f_evaluations+=[f_eval]            \n",
    "            bmrk+=[tot_best]\n",
    "            \n",
    "        #continuous PSO\n",
    "        for i in range(0,n_pop):\n",
    "            ind=np.where(np.array(particle_number)==i)[0][0]\n",
    "            \n",
    "            #continuous part\n",
    "            population[ind],velocities[ind] = continuous_PSO(population[ind], ind, velocities[ind], population, particle_best_position, \n",
    "                                                       d_discr, d_cont, w, minimum, maximum, cog = 2)\n",
    "                        \n",
    "            \n",
    "            #discrete part\n",
    "            population[ind],probabilities = discrete_PSO(population[ind], ind, probabilities, population, particle_best_position, \n",
    "                                                       d_discr, d_cont, alpha, granularity , \n",
    "                                                       np.linspace(minimum, maximum, granularity))\n",
    "                       \n",
    "            f_eval+=1\n",
    "            #calculate the value\n",
    "            values[ind] = function(population[ind][:d_discr],population[ind][-d_cont:],d_discr+d_cont,rot_matrix)\n",
    "            #substitute in particle_best if it is better\n",
    "            if values[ind] < particle_best_values[ind]:\n",
    "                particle_best_values[ind] = values[ind]\n",
    "                particle_best_position[ind] = population[ind]\n",
    "            \n",
    "            #sort everything\n",
    "            particle_number, population, values, particle_best_position, particle_best_values,velocities,w,alpha,w_avg,alpha_avg = pop_sorting(\n",
    "                                                                                        particle_number, population,\n",
    "                                                                                        values, particle_best_position,\n",
    "                                                                                        particle_best_values,velocities,w,alpha,w_avg,alpha_avg)\n",
    "        #exit if too many function evaluations\n",
    "        if f_eval>max_fitness_eval:\n",
    "            return bmrk,f_evaluations          \n",
    "        \n",
    "        \n",
    "        \n",
    "        #procedure to tune parameters\n",
    "        #values ordered according to particle_number\n",
    "        sort_ind = sorted(range(len(particle_number)), key=lambda k: particle_number[k], reverse=False)\n",
    "        vals = [values[i] for i in sort_ind]\n",
    "        for i in range(0,n_pop):\n",
    "            k=np.where(np.array(particle_number)==i)[0][0]\n",
    "            if vals[i]<prev_values[i]:\n",
    "                w_hist[i]+=[w[k]]\n",
    "                alpha_hist[i]+=[alpha[k]]\n",
    "            w_avg[k]=np.mean(w_hist[i])\n",
    "            alpha_avg[k]=np.mean(alpha_hist[i])\n",
    "    return bmrk,f_evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "16ec16d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of use\n",
    "#PSO_mv(500,alpine1_func_rotated,generate_random_rotation_matrix(50),50,25,25,-10,10,21,max_fitness_eval=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bccc54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
